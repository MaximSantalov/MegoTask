{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid,StratifiedKFold, KFold\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "RANDOM_STATE = 2\n",
    "cat_features = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_train():\n",
    "    start = time.time()\n",
    "    data = pd.merge(pd.read_excel('task2.xlsb', sheet_name = \"data1\", engine='pyxlsb'),\\\n",
    "                    pd.read_excel('task2.xlsb', sheet_name = \"data2\", engine='pyxlsb'), how = \"outer\")\n",
    "    print(data.shape)\n",
    "    print(data.columns)\n",
    "    data = data.dropna()\n",
    "    print(data.shape)\n",
    "    columns = ['session_id', 'channel_id', 'weekday_session', 'hour_session',\n",
    "       'session_price', 'flight_type', 'multifr_type', 'validating_airline_id',\n",
    "       'adults_count', 'children_count', 'infants_count', 'service_class_id',\n",
    "       'days_to_flight', 'departure_day', 'departure_weekday',\n",
    "       'departure_hour', 'adapter_id', 'from_destination_id',\n",
    "       'to_destination_id', 'meta_flight_type']\n",
    "    \n",
    "    X = data[columns]\n",
    "    y = data['target_result']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y, \n",
    "                                                        shuffle=True,\n",
    "                                                        random_state=RANDOM_STATE,\n",
    "                                                        train_size=0.8\n",
    "                                                        )\n",
    "   # print(X_train.head())\n",
    "    \n",
    "    print( \"TIME IS \" , time.time() - start) \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "    \n",
    "X_train, X_test, y_train, y_test = get_data_train()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_predict():\n",
    "    start = time.time()\n",
    "    #data = pd.merge(pd.read_excel('task2.xlsb', sheet_name = 2, engine='pyxlsb'),\\\n",
    "    data = pd.read_excel('task2.xlsb', sheet_name = 'test_data', engine='pyxlsb')\n",
    "    #, \\\n",
    "     #               how = \"outer\")\n",
    "    print(data.shape)\n",
    "    print(data.columns)\n",
    "    print(data.shape)\n",
    "    columns = ['session_id', 'channel_id', 'weekday_session', 'hour_session',\n",
    "       'session_price', 'flight_type', 'multifr_type', 'validating_airline_id',\n",
    "       'adults_count', 'children_count', 'infants_count', 'service_class_id',\n",
    "       'days_to_flight', 'departure_day', 'departure_weekday',\n",
    "       'departure_hour', 'adapter_id', 'from_destination_id',\n",
    "       'to_destination_id', 'meta_flight_type']\n",
    "    \n",
    "    X = data[columns]\n",
    "                            \n",
    "   # print(X_train.head())\n",
    "    \n",
    "    print( \"TIME IS \" , time.time() - start) \n",
    "    return X\n",
    "\n",
    "\n",
    "    \n",
    "X_predict = get_data_predict()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkIt(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(X, y, X_test, param, y_test, cat_features, n_splits=5):\n",
    "    #skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    acc = []\n",
    "    predict = None\n",
    "    \n",
    "    X_train_ind = chunkIt(X.index, n_splits)\n",
    "    X_test_ind = chunkIt(X_test.index, n_splits)\n",
    "    y_train_ind = chunkIt(y.index, n_splits)\n",
    "    y_test_ind = chunkIt(y_test.index, n_splits)\n",
    "\n",
    "\n",
    "    for i in range(len(X_train_ind)):\n",
    "       \n",
    "        X_train, X_valid = X.loc[X_train_ind[i]], X_test.loc[X_test_ind[i]]\n",
    "        y_train, y_valid = y.loc[y_train_ind[i]], y_test.loc[y_test_ind[i]]\n",
    "        \n",
    "        clf = CatBoostClassifier(iterations=500,\n",
    "                                loss_function = param['loss_function'],\n",
    "                                depth=param['depth'],\n",
    "                                l2_leaf_reg = param['l2_leaf_reg'],\n",
    "                                eval_metric = 'Accuracy',\n",
    "                                leaf_estimation_iterations = 10,\n",
    "                                use_best_model=True,\n",
    "                                logging_level='Silent'\n",
    "        )\n",
    "        \n",
    "        clf.fit(X_train, \n",
    "                y_train,\n",
    "               # cat_features=cat_features,\n",
    "                eval_set=(X_valid, y_valid)\n",
    "        )\n",
    "        \n",
    "        y_pred = clf.predict(X_valid)\n",
    "        accuracy = accuracy_score(y_valid, y_pred)\n",
    "        acc.append(accuracy)\n",
    "        \n",
    "    return sum(acc)/n_splits\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_GridSearchCV(X, y, X_test, params, y_test, cat_features, n_splits=10):\n",
    "    ps = {'acc':0,\n",
    "          'param': []\n",
    "    }\n",
    "    \n",
    "    predict=None\n",
    "    \n",
    "    for prms in tqdm(list(ParameterGrid(params)), ascii=True, desc='Params Tuning:'):\n",
    "                          \n",
    "        acc = cross_val(X, y, X_test, prms, y_test, cat_features, n_splits=5)\n",
    "\n",
    "        if acc>ps['acc']:\n",
    "            ps['acc'] = acc\n",
    "            ps['param'] = prms\n",
    "    print('Acc: '+str(ps['acc']))\n",
    "    print('Params: '+str(ps['param']))\n",
    "    \n",
    "    return ps['param']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t, X_test_t, y_train_t, y_test_t = X_train[:100], X_test[:100], y_train[:100], y_test[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'depth':[2, 3, 4, 8],\n",
    "          'loss_function': ['Logloss', 'CrossEntropy'],\n",
    "          'l2_leaf_reg':np.logspace(-20, -19, 3),\n",
    "          'learning_rate': [0.05, 0.1]\n",
    "         }\n",
    "    \n",
    "param = catboost_GridSearchCV(X_train, y_train, X_test, params, y_test, cat_features)\n",
    "    \n",
    "    \n",
    "#param = make_grid(clf, X_train_t, y_train_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CatBoostClassifier(iterations=500,\n",
    "                            loss_function = param['loss_function'],\n",
    "                            depth=param['depth'],\n",
    "                            l2_leaf_reg = param['l2_leaf_reg'],\n",
    "                            eval_metric = 'Accuracy',\n",
    "                            leaf_estimation_iterations = 10,\n",
    "                            use_best_model=True\n",
    "    )\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train,\n",
    "                                                    y_train, \n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=RANDOM_STATE,\n",
    "                                                    train_size=0.8,\n",
    "                                                    stratify=y_train\n",
    "    )\n",
    "clf.fit(X_train, \n",
    "        y_train,\n",
    "        #cat_features=cat_features,\n",
    "        logging_level='Silent',\n",
    "        eval_set=(X_valid, y_valid)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = clf.predict(X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_excel(\"solution.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
